{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is a Decision Tree fit?\n",
    "\n",
    "* Which variables to include on the tree?\n",
    "* How to choose the threshold?\n",
    "* When to stop the tree?\n",
    "\n",
    "**Key idea is that we want to choose the feature that has the lowest \"impurity\" to split our tree, thus our tree can reach the decision as fast as possible with smallest height possible.**\n",
    "\n",
    "One way to measure impurity is using **Gini index** (another one is entropy but which measure very similar thing) with the following formula:\n",
    "\n",
    "$$ I_{G} = 1 - \\sum_{i=1}^{c} p_{i}^{2} $$\n",
    "\n",
    "where $c$ is number of classes, and $p_{i}$ is the probability of each class.  For example, let's say our X is <code>[[2],[3],[10],[19]]</code> and y is <code>[0, 0, 1, 1]</code>.  That is, if a node has 4 samples, and 2 samples are of class cancer, and 2 samples are of no cancer, then the probability of each class is\n",
    "\n",
    "$$p_{cancer}=(2/4)^2 = 0.25$$\n",
    "\n",
    "$$p_{no_cancer}=(2/4)^2 = 0.25$$   \n",
    "\n",
    "Thus the gini index of this node is\n",
    "\n",
    "$$ I_{G} = 1 - (0.25 + 0.25) = 0.5 $$\n",
    "\n",
    "Then we need to decide how to best split this node so we can get the lowest gini (highest purity) children.\n",
    "\n",
    "For example, if we split this sample with $x < 3$: we will get left node X as <code>[[2]]</code> and y as <code>[0]</code> and the right node X as <code>[[3],[10],[19]]</code> and y as <code>[0, 1, 1]</code>.  The weighted gini of the children are \n",
    "\n",
    "$$ 1/4*I_{leftG} + 3/4 * I_{rightG} =  $$\n",
    "$$ 1/4 * (1 - (1/1)^2) + 3/4 * (1 - (1/3)^2 - (2/3)^2) = 0.33 $$\n",
    "\n",
    "Hmm...but we know we can split better, right?  Let's try $x < 4$: we will get left node X as <code>[[2],[3]]</code> and y as <code>[0, 0]</code> and the right node X as <code>[[10],[19]]</code> and y as <code>[1, 1]</code>.  If you do the math right, the gini is 0!\n",
    "\n",
    "$$ 2/4 * (1 - (2/2)^2) + 2/4 * (1 - (2/2)^2 ) = 0 $$\n",
    "\n",
    "Thus, in conclusion, we can say that spliting $x<4$ is a much better split than $x<3$.  In practice, to really find the best split, it is an exhaustive and greedy algorithm, in which we have to iterate and check every value on each feature as a candidate split, find the gini index.  \n",
    "\n",
    "#### How do we find all threshold for continuous values?\n",
    "\n",
    "We can first sort.  Then we are identify critical value using the midpoint between all consecutive values.  For example, given X is <code>[[2],[3],[10],[19]]</code>, the critical value to compare is 2.5, 6.5 and 14.5.\n",
    "\n",
    "The code can be implemented in several ways.  Example are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[2], [3], [10], [19]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n2.5, 6.5, 14.5\\n\\n[2]    [3][10][19]\\n[0]    [0][1][1]\\n\\n[2][3]   [10][19]\\n[0][0]   [1][1]\\n\\n[2][3][10]  [19]\\n[0][0][1]   [1]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2.5, 6.5, 14.5\n",
    "\n",
    "[2]    [3][10][19]\n",
    "[0]    [0][1][1]\n",
    "\n",
    "[2][3]   [10][19]\n",
    "[0][0]   [1][1]\n",
    "\n",
    "[2][3][10]  [19]\n",
    "[0][0][1]   [1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_split(X, y, n_classes):\n",
    "    \n",
    "    m, n = X.shape  #samples, feature\n",
    "    \n",
    "    if m <= 1:\n",
    "        return None, None\n",
    "    \n",
    "    feature_ix, threshold = None, None\n",
    "    \n",
    "    sample_per_class_parent = [np.sum(y == c) for c in range(n_classes)]  #[2, 2]\n",
    "    \n",
    "    #gini index of the parent\n",
    "    best_gini = 1.0 - sum((m_i / m) ** 2 for m_i in sample_per_class_parent)\n",
    "    \n",
    "    for feature in range(n):\n",
    "        \n",
    "        sample_sorted = sorted(X[:, feature]) #[2, 3, 10, 19]\n",
    "        sort_idx      = np.argsort(X[:, feature])\n",
    "        y_sorted      = y[sort_idx] #[0, 0, 1, 1]\n",
    "        \n",
    "        sample_per_class_left  = [0] * n_classes #[0, 0]\n",
    "        sample_per_class_right = sample_per_class_parent #[2, 2]\n",
    "        \n",
    "        for i in range(1, m):  #1, 2, 3  \n",
    "            c = y_sorted[i - 1] #[0]\n",
    "            \n",
    "            sample_per_class_left[c]  += 1  #[1, 0]\n",
    "            sample_per_class_right[c] -= 1  #[1, 2]\n",
    "            \n",
    "            gini_left = 1.0 - sum(\n",
    "                (sample_per_class_left[x] / i) ** 2 for x in range(n_classes)\n",
    "            )\n",
    "            \n",
    "            gini_right = 1.0 - sum(\n",
    "                (sample_per_class_right[x] / (m - i)) ** 2 for x in range(n_classes)\n",
    "            )\n",
    "            \n",
    "            weighted_gini = ((i / m) * gini_left) + ( (m - i) /m) * gini_right\n",
    "            \n",
    "            #in case the value are the same, we do not split\n",
    "            #both have to end up on the same side of the split\n",
    "            if sample_sorted[i] == sample_sorted[i - 1]:\n",
    "                continue\n",
    "            \n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                feature_ix = feature\n",
    "                threshold = (sample_sorted[i] + sample_sorted[i -1]) / 2 \n",
    "    \n",
    "    return feature_ix, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[2],[3],[10],[19]])\n",
    "y = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, threshold = find_split(X, y, len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(Xtrain, ytrain, n_classes, depth=0): \n",
    "    \n",
    "    n_samples, n_features = Xtrain.shape\n",
    "    num_samples_per_class = [np.sum(ytrain == i) for i in range(n_classes)]\n",
    "    #predicted class using the majority of sample class\n",
    "    predicted_class = np.argmax(num_samples_per_class) \n",
    "    \n",
    "    #define the parent node\n",
    "    node = Node(\n",
    "        gini = 1 - sum((np.sum(y == c) / n_samples) ** 2 for c in range(n_classes)),\n",
    "        predicted_class=predicted_class,\n",
    "        num_samples = ytrain.size,\n",
    "        num_samples_per_class = num_samples_per_class,\n",
    "        )\n",
    "    \n",
    "    #perform recursion\n",
    "    feature, threshold = find_split(Xtrain, ytrain, n_classes)\n",
    "    \n",
    "    if feature is not None:\n",
    "        indices_left = X[:, feature] < threshold\n",
    "        X_left, y_left   = X[indices_left], y[indices_left]\n",
    "        X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "        \n",
    "        #take note for later decision\n",
    "        node.feature_index = feature\n",
    "        node.threshold = threshold\n",
    "        node.left  = fit(X_left, y_left, n_classes, depth + 1)\n",
    "        node.right = fit(X_right, y_right, n_classes, depth + 1)\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict, it is as simple as moving \n",
    "#through the tree \n",
    "def predict(sample, tree):\n",
    "    while tree.left:\n",
    "        if sample[tree.feature_index] < tree.threshold:\n",
    "            tree = tree.left\n",
    "        else:\n",
    "            tree = tree.right\n",
    "    return tree.predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit starting with tree depth = 0\n",
    "Xtrain = np.array([[2, 5],[3, 5],[10, 5],[19, 5]])\n",
    "ytrain = np.array([0, 0, 1, 1])\n",
    "Xtest = np.array(([[4, 6],[6, 9],[9, 2],[12, 8]]))\n",
    "ytest = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = fit(Xtrain, ytrain, len(set(ytrain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x113ce48d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [predict(x, tree) for x in Xtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree feature ind:  0\n",
      "Tree threshold:  6.5\n",
      "Pred:  [0 0 1 1]\n",
      "ytest:  [0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tree feature ind: \", tree.feature_index)\n",
    "print(\"Tree threshold: \", tree.threshold)\n",
    "print(\"Pred: \", np.array(pred))\n",
    "print(\"ytest: \", ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision is prone to overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
