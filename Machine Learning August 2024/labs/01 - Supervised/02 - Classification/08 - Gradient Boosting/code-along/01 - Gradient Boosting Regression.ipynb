{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis function\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}) = h_0(\\mathbf{x}^{(i)}) + \\alpha_1h_1(\\mathbf{x}^{(i)}) + \\cdots + \\alpha_s h_s(\\mathbf{x}^{(i)})\n",
    "$$\n",
    "\n",
    "1. No alpha is applied to the first predictor, because the learning is \"sequential\"\n",
    "2. In addition, all alpha shares the same number.  Here, alpha is like the learning rate in regression.\n",
    "\n",
    "## Main idea: fitting the residuals\n",
    "\n",
    "$$h_0(\\mathbf{x}^{(i)}) + \\text{residual}_0 = y^{(i)} $$\n",
    "$$ \\text{residual}_0 =  y^{(i)} - h_0(\\mathbf{x}^{(i)}) $$\n",
    "\n",
    "## Summary of steps\n",
    "\n",
    "1. Initialize the model as simply mean or some constant\n",
    "2. Predict and calculate the residual\n",
    "3. Let the next model fit the residual\n",
    "4. Predict using the combined models and calculate the residual\n",
    "5. Let the next model fit this residual\n",
    "6. Simply repeat 4-5 until stopping criteria is reached"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(y, h):\n",
    "    return y - h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, models):\n",
    "    learning_rate = 0.1\n",
    "    f0 = models[0].predict(X)\n",
    "    boosting = sum(learning_rate * model.predict(X) for model in models[1:])\n",
    "    return f0 + boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, models):\n",
    "    models_trained = []\n",
    "    \n",
    "    #using DummyRegressor is a good technique for starting model\n",
    "    first_model = DummyRegressor(strategy='mean')\n",
    "    first_model.fit(X, y)\n",
    "    models_trained.append(first_model)\n",
    "    \n",
    "    #fit the estimators\n",
    "    for i, model in enumerate(models):\n",
    "        y_pred = predict(X, models_trained)\n",
    "        residual = grad(y, y_pred)\n",
    "        model.fit(X, residual)\n",
    "        models_trained.append(model)\n",
    "    return models_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use our scratch code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 200\n",
    "tree_params = {'max_depth': 1}\n",
    "models = [DecisionTreeRegressor(**tree_params) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the models\n",
    "models = fit(X_train, y_train, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "y_pred = predict(X_test, models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our MSE:  2714.1889891700657\n"
     ]
    }
   ],
   "source": [
    "#print metrics\n",
    "print(\"Our MSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
