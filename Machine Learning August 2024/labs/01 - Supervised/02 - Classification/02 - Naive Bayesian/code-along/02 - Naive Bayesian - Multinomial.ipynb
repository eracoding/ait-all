{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian - Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y|w) = \\frac{P(w|y)P(y)}{P(w)}\n",
    "$$\n",
    "\n",
    "$$ P(w_i \\in train \\mid y=k) = \\frac{count(w_i, k)}{\\sum_{i=1}^{n} count(w_i, k)} $$\n",
    "    \n",
    "Example:\n",
    "\n",
    "| | docID  | words in doc    | China?   |    \n",
    "|---:|:-------------|:-----------|:------|\n",
    "| Training set | 1  | Chinese Beijing Chinese       | Yes   |\n",
    "|  | 2  | Chinese Chinese Shanghai    | Yes  |\n",
    "|  | 3  | Chinese Macao    | Yes   |\n",
    "|  | 4  | Tokyo Japan Chinese   | No   |\n",
    "| Test set | 5  | Chinese Chinese Chinese Tokyo Japan    | ?   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array([\n",
    "    'Chinese Beijing Chinese',\n",
    "    'Chinese Chinese Shanghai',\n",
    "    'Chinese Macao',\n",
    "    'Tokyo Japan Chinese',\n",
    "])\n",
    "\n",
    "test = np.array([\n",
    "    'Chinese Chinese Chinese Tokyo Japan'\n",
    "])\n",
    "\n",
    "train_target = np.array([1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train    = vectorizer.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['beijing' 'chinese' 'japan' 'macao' 'shanghai' 'tokyo']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature names:\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type:\", type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(X_class):\n",
    "    return ((X_class.sum(axis=0)) /  np.sum(X_class.sum(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_class1 = X_train[train_target==1]\n",
    "X_train_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_class0 = X_train[train_target==0]\n",
    "X_train_class0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_class1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 5, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_class1.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(X_train_class1.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.125, 0.625, 0.   , 0.125, 0.125, 0.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood1 = likelihood(X_train_class1)\n",
    "likelihood1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.33333333, 0.33333333, 0.        , 0.        ,\n",
       "         0.33333333]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood0 = likelihood(X_train_class0)\n",
    "likelihood0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace smoothing\n",
    "\n",
    "$$ P(w_i \\in train \\mid y=k) = \\frac{count(w_i, k) + 1}{\\sum_{i=1}^{n} count(w_i, k) + n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(X_class, laplace=1):\n",
    "    return (((X_class.sum(axis=0)) + laplace) /  np.sum(X_class.sum(axis=0) + laplace))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood1 = likelihood(X_train_class1)\n",
    "likelihood0 = likelihood(X_train_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0.11111111, 0.22222222, 0.22222222, 0.11111111, 0.11111111,\n",
       "          0.22222222]]),\n",
       " matrix([[0.14285714, 0.42857143, 0.07142857, 0.14285714, 0.14285714,\n",
       "          0.07142857]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood0, likelihood1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors\n",
    "\n",
    "$$P(y = k) = \\frac{\\Sigma_{i=1}^{m}1(y=k)}{m} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  [1 1 1 0]\n",
      "Prior 1 (P(y=1)):  0.75\n",
      "Prior 0 (P(y=0)):  0.25\n"
     ]
    }
   ],
   "source": [
    "prior1 = len(train_target[train_target==1])/len(train_target)\n",
    "prior0 = len(train_target[train_target==0])/len(train_target)\n",
    "\n",
    "print(\"Target: \", train_target)\n",
    "print(\"Prior 1 (P(y=1)): \", prior1)\n",
    "print(\"Prior 0 (P(y=0)): \", prior0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total likelihood\n",
    "\n",
    "$$ P(w \\in test \\mid y=k) = \\prod_{i=1}^{n} P(w_i \\mid y=k)^{\\text{freq of }w_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test)\n",
    "X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.14285714, 0.42857143, 0.07142857, 0.14285714, 0.14285714,\n",
       "         0.07142857]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004016183732968405"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxtest_y1 = np.prod(np.power(likelihood1, X_test.toarray()))\n",
    "pxtest_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005419228098697689"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxtest_y0 = np.prod(np.power(likelihood0, X_test.toarray()))\n",
    "pxtest_y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinese Chinese Chinese Tokyo Japan'], dtype='<U35')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "$$P (y = k \\mid w \\in test) = P(y=k)\\prod_{i=1}^{n} P(w_i \\mid y=k)^{\\text{freq of }w_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "py1_x = prior1 * pxtest_y1\n",
    "py0_x = prior0 * pxtest_y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00030121377997263036, 0.00013548070246744223)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py1_x, py0_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chinese Chinese Chinese Tokyo Japan'], dtype='<U35')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conclusion, our test sample Chinese Chinese Chinese Tokyo Japan --> China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-8.107690312843909, -8.906681345001262)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(py1_x), np.log(py0_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log probability\n",
    "   \n",
    "$$P (y = k \\mid w \\in test) = \\log \\ P(y=k) + \\sum_{i=1}^{n} (\\text{freq of }w_i) * \\log \\ p(w_i \\mid y=k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_test | y = 1):  [[-7.82000824]]\n",
      "P(X_test | y = 0):  [[-7.52038698]]\n"
     ]
    }
   ],
   "source": [
    "pxtest_y1 = X_test.toarray() @ np.log(likelihood1.T)\n",
    "pxtest_y0 = X_test.toarray() @ np.log(likelihood0.T)\n",
    "\n",
    "print(\"P(X_test | y = 1): \", pxtest_y1)\n",
    "print(\"P(X_test | y = 0): \", pxtest_y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "py1_x = np.log(prior1) + pxtest_y1\n",
    "py0_x = np.log(prior0) + pxtest_y0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|X_test) = p(y=1) + p(X_test|y=1):  [[-8.10769031]]\n",
      "P(y=0|X_test) = p(y=0) + p(X_test|y=0):  [[-8.90668135]]\n"
     ]
    }
   ],
   "source": [
    "print(\"P(y=1|X_test) = p(y=1) + p(X_test|y=1): \", py1_x)\n",
    "print(\"P(y=0|X_test) = p(y=0) + p(X_test|y=0): \", py0_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jono@mac-ak-24.rtsg.mot.com (Jon Ogden)\n",
      "Subject: Re: Losing your temper is not a Christian trait\n",
      "Organization: Motorola LPA Development\n",
      "Lines: 26\n",
      "\n",
      "In article <Apr.23.02.55.47.1993.3138@geneva.rutgers.edu>, jcj@tellabs.com\n",
      "(jcj) wrote:\n",
      "\n",
      "> I'd like to remind people of the withering of the fig tree and Jesus\n",
      "> driving the money changers et. al. out of the temple.  I think those\n",
      "> were two instances of Christ showing anger (as part of His human side).\n",
      "> \n",
      "Yes, and what about Paul saying:\n",
      "\n",
      "26 Be ye angry, and sin not: let not the sun go down upon your wrath:\n",
      "(Ephesians 4:26).\n",
      "\n",
      "Obviously then, we can be angry w/o sinning.\n",
      "\n",
      "Jon\n",
      "\n",
      "------------------------------------------------\n",
      "Jon Ogden         - jono@mac-ak-24.rtsg.mot.com\n",
      "Motorola Cellular - Advanced Products Division\n",
      "Voice: 708-632-2521      Data: 708-632-6086\n",
      "------------------------------------------------\n",
      "\n",
      "They drew a circle and shut him out.\n",
      "Heretic, Rebel, a thing to flout.\n",
      "But Love and I had the wit to win;\n",
      "We drew a circle and took him in.\n",
      "\n",
      "Target:  2\n",
      "X_train:    (0, 14822)\t1\n",
      "  (0, 18774)\t2\n",
      "  (0, 20502)\t2\n",
      "  (0, 4688)\t2\n",
      "  (0, 1572)\t2\n",
      "  (0, 27916)\t2\n",
      "  (0, 21988)\t2\n",
      "  (0, 9095)\t3\n",
      "  (0, 18765)\t3\n",
      "  (0, 23326)\t2\n",
      "  (0, 30617)\t1\n",
      "  (0, 26562)\t1\n",
      "  (0, 20308)\t1\n",
      "  (0, 35183)\t2\n",
      "  (0, 31463)\t1\n",
      "  (0, 18370)\t1\n",
      "  (0, 22932)\t3\n",
      "  (0, 8590)\t1\n",
      "  (0, 32244)\t1\n",
      "  (0, 23591)\t1\n",
      "  (0, 22013)\t2\n",
      "  (0, 20366)\t1\n",
      "  (0, 11327)\t1\n",
      "  (0, 20065)\t1\n",
      "  (0, 1655)\t3\n",
      "  :\t:\n",
      "  (0, 8236)\t1\n",
      "  (0, 4416)\t1\n",
      "  (0, 25675)\t1\n",
      "  (0, 11891)\t1\n",
      "  (0, 33990)\t1\n",
      "  (0, 2879)\t2\n",
      "  (0, 2691)\t2\n",
      "  (0, 1631)\t1\n",
      "  (0, 10677)\t1\n",
      "  (0, 2645)\t1\n",
      "  (0, 31737)\t1\n",
      "  (0, 12166)\t2\n",
      "  (0, 8666)\t2\n",
      "  (0, 29122)\t1\n",
      "  (0, 16610)\t2\n",
      "  (0, 16493)\t1\n",
      "  (0, 26646)\t1\n",
      "  (0, 31753)\t1\n",
      "  (0, 14421)\t1\n",
      "  (0, 7576)\t1\n",
      "  (0, 20341)\t1\n",
      "  (0, 16025)\t1\n",
      "  (0, 34678)\t1\n",
      "  (0, 34604)\t1\n",
      "  (0, 32091)\t1\n",
      "y_train:  2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups()\n",
    "data.target_names\n",
    "\n",
    "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
    "              'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "print(train.data[0]) #first 300 words\n",
    "print(\"Target: \", train.target[0])  #start with 1, soc.religion.christian\n",
    "\n",
    "#transform our X to frequency data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train.data)\n",
    "X_test = vectorizer.transform(test.data)\n",
    "X_test = X_test.toarray()  #vectorizer gives us a sparse matrix; convert back to dense matrix\n",
    "\n",
    "y_train = train.target\n",
    "y_test = test.target\n",
    "\n",
    "print(\"X_train: \", X_train[0])\n",
    "print(\"y_train: \", y_train[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculating likelihood anrd prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(X_class, laplace=1):\n",
    "    return ((X_class.sum(axis=0)) + laplace) / (np.sum(X_class.sum(axis=0) + laplace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(X_class, m):\n",
    "    return X_class.shape[0] / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, y_train):\n",
    "    m, n = X_train.shape\n",
    "    classes = np.unique(y_train)  #list of class\n",
    "    k = len(classes) #number of class\n",
    "    \n",
    "    priors = np.zeros(k) #prior for each classes\n",
    "    likelihoods = np.zeros((k, n)) #likehood for each class of each feature\n",
    "    \n",
    "    for idx, label in enumerate(classes):\n",
    "        X_train_c = X_train[y_train==label]\n",
    "        priors[idx] = prior(X_train_c, m)\n",
    "        likelihoods[idx, :] = likelihood(X_train_c)\n",
    "    return priors, likelihoods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, priors, likelihoods, classes):\n",
    "    return np.log(priors) + X_test @ np.log(likelihoods.T) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Let's use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors, likelihoods = fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_test)\n",
    "yhat = predict(X_test, priors, likelihoods, classes)\n",
    "yhat = np.argmax(yhat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9168994413407822\n",
      "=========Average precision score=======\n",
      "Class 0 score:  0.9152047938418233\n",
      "Class 1 score:  0.9069918620723723\n",
      "Class 2 score:  0.8429395016564877\n",
      "Class 3 score:  0.7277310085946386\n",
      "=========Classification report=======\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       389\n",
      "           1       0.94      0.96      0.95       394\n",
      "           2       0.87      0.95      0.91       398\n",
      "           3       0.92      0.74      0.82       251\n",
      "\n",
      "    accuracy                           0.92      1432\n",
      "   macro avg       0.92      0.90      0.91      1432\n",
      "weighted avg       0.92      0.92      0.92      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import average_precision_score, classification_report\n",
    "\n",
    "n_classes = len(np.unique(y_test))\n",
    "\n",
    "print(\"Accuracy: \", np.sum(yhat == y_test)/len(y_test))\n",
    "\n",
    "print(\"=========Average precision score=======\")\n",
    "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "yhat_binarized = label_binarize(yhat, classes=[0, 1, 2, 3])\n",
    "\n",
    "for i in range(n_classes):\n",
    "    class_score = average_precision_score(y_test_binarized[:, i], yhat_binarized[:, i])\n",
    "    print(f\"Class {i} score: \", class_score)\n",
    "    \n",
    "print(\"=========Classification report=======\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('teaching_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "becc4c8e5ad229b2591d820334d85e3db0111492344629bf57f272470dce75a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
