{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Analyze and Preprocess\n",
    "\n",
    "Now that you know how to perform a basic analyze and preprocess, let's put that in the practice.\n",
    "\n",
    "Here we will use a sample from DEAP dataset, `s01.dat`.\n",
    "\n",
    "Download the sample [here](https://drive.google.com/file/d/19XbYM6WFT9L2mD5l_66mKQzHNZnhee2t/view?usp=sharing). Use your AIT account.\n",
    "\n",
    "While we wait for the file to download, here is the information about the dataset.\n",
    "\n",
    "[DEAP](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/)\n",
    "\n",
    "![alt](https://www.eecs.qmul.ac.uk/mmv/datasets/deap/img/graph.png)\n",
    "\n",
    "A Database for Emotion Analysis using Physiological Signals (DEAP) consists of 32 participants/samples. The data is an EEG (and other Physiological responses) record of someone watching a video that induce certain emotion. Thus, Independent Variable (IV) is EEG and Dependent variable (DV) is Emotion. \n",
    "\n",
    "Each participant watch 40 videos. Each video is 60 seconds long. The EEG sampling rate is 128 Hz. The trial has 3 seconds pre-trial/fixation. Thus, each trial is 63 seconds and 63 $\\times$ 128 = 8064 time samples.\n",
    "\n",
    "Now, about EEG recording. Electroencephalogram (EEG) is an electrical activity of the brain which captures brain activity. We know certain part of the brain is correlated to certain function of a human. Thus, we put multiple sensor on different point of the brain. The sensor/electrode placement guide/convention is 10-20 International system.\n",
    "\n",
    "![alt](https://www.researchgate.net/publication/324361441/figure/fig1/AS:618934365597697@1524576860370/The-10-20-International-system-of-EEG-electrode-placement.png)\n",
    "\n",
    "The number of electrode and which place is used depends on the researcher/cost/experiment also the sampling rate. Thus, we have to read their document to find out which electrode placement and sampling rate is used.\n",
    "\n",
    "For this DEAP the electrode placement are the following.\n",
    "\n",
    "- 1:\tFp1\t\n",
    "- 2:\tAF3\n",
    "- 3:\tF3\n",
    "- 4:\tF7\n",
    "- 5:\tFC5\n",
    "- 6:\tFC1\n",
    "- 7:\tC3\n",
    "- 8:\tT7\n",
    "- 9:\tCP5\n",
    "- 10:\tCP1\n",
    "- 11:\tP3\n",
    "- 12:\tP7\n",
    "- 13:\tPO3\n",
    "- 14:\tO1\n",
    "- 15:\tOz\n",
    "- 16:\tPz\n",
    "- 17:\tFp2\n",
    "- 18:\tAF4\n",
    "- 19:\tFz\n",
    "- 20:\tF4\n",
    "- 21:\tF8\n",
    "- 22:\tFC6\n",
    "- 23:\tFC2\n",
    "- 24:\tCz\n",
    "- 25:\tC4\n",
    "- 26:\tT8\n",
    "- 27:\tCP6\n",
    "- 28:\tCP2\n",
    "- 29:\tP4\n",
    "- 30:\tP8\n",
    "- 31:\tPO4\n",
    "- 32:\tO2\n",
    "\n",
    "- 33:\thEOG (horizontal EOG, hEOG1 - hEOG2)\t\n",
    "- 34:\tvEOG (vertical EOG, vEOG1 - vEOG2)\n",
    "- 35:\tzEMG (Zygomaticus Major EMG, zEMG1 - zEMG2)\n",
    "- 36:\ttEMG (Trapezius EMG, tEMG1 - tEMG2)\n",
    "- 37:\tGSR (values from Twente converted to Geneva format (Ohm))\n",
    "- 38:\tRespiration belt\n",
    "- 39:\tPlethysmograph\n",
    "- 40:\tTemperature\n",
    "\n",
    "Out of 40 channels, there are 32 EEG channels.\n",
    "\n",
    "In summary, the IV has 40 videos, 40 channels, and 8064 time samples (40, 40, 8064)\n",
    "\n",
    "The DV (labels) has a shape (40, 4) which is 40 videos and 4 emotions (valence, arousal, dominance, liking)\n",
    "\n",
    "You probably are done downloading by now. Let's start coding!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Objective</u>\n",
    "1. Get your hands dirty with signal analyze and preprocessing on the real dataset.\n",
    "2. Prepare data for classification using `SVM` from `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Easy, move the downloaded `s01.dat` to the `dataset` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists('dataset/s01.dat'), \"Well, you probably forget to move the s01.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Read the `s01.dat` using the given function and confirmed the shape.\n",
    "\n",
    "The IV is (40,40,8064)\n",
    "\n",
    "The DV is (40,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path:str) -> np.ndarray:\n",
    "    return pickle.load(open(path, 'rb'), encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Let's plot the signal and FFT of first video, first channel.\n",
    "\n",
    "The signal plot should have x-axis as `time (second)` and the FFT plot should have x-axis as `frequency (Hz)`. Based on the sampling rate, the range of frequency to plot is 0 - 64 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Does the signal contain all frequencies?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Plot the STFT of the first video of the first 2 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Now, we want to train the SVM model and see whether the model can classify emotion based on the EEG signal.\n",
    "\n",
    "Let's plan this ahead. \n",
    "\n",
    "The sklearn model accept the IV shape of `(n_samples, n_features)`. The `n_samples` is `videos`. Then, what is `n_features`?\n",
    "\n",
    "This is where we need to do research about EEG.\n",
    "\n",
    "But for now, I will tell you that EEG consists of 5 frequencies bands and each band has a correlation to certain state of Human emotion.\n",
    "\n",
    "Common EEG bands are\n",
    "\n",
    "1. Delta [0-4]\n",
    "2. Theta [4-8]\n",
    "3. Alpha [8-14]\n",
    "4. Beta  [14-30]\n",
    "5. Gamme [30-$\\infty$]\n",
    "\n",
    "The number and range are different among the papers but not way off.\n",
    "\n",
    "Since we only have 40 trials, the data have 32 X 5 bands which is 160 features. Based on the learning theory, this won't work. But anyway, we do this as a practice.\n",
    "\n",
    "So this task, preprocess the IV into a shape of (40, 160)\n",
    "\n",
    "*Don't forget to ignore the first 3 seconds*\n",
    "\n",
    "*Don't forget to only pick the EEG channels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "\n",
    "This is also easy, prepare DV. You can pick any emotion you want to train/build.\n",
    "\n",
    "However, the data in the DV is a score range of [0-10], not a binary class. \n",
    "\n",
    "I will pick 'valence' and 5 as a threshold.\n",
    "\n",
    "*The shape of 'labels' coresponse to this (valence, arousal, dominance, liking)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8\n",
    "\n",
    "Now that we are ready to train SVM. Just train it.\n",
    "\n",
    "Don't forget to split train/test set. Because we only have 40 samples, let's do test size = 0.15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27768773b483d82a9b2b839e3fa80b1be5789db7fd78df4eedef2df266871616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
