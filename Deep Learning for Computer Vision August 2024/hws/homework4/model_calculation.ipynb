{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = np.array([[1], [1]])\n",
    "\n",
    "output1 = np.array([[1]]).T\n",
    "\n",
    "alpha = 1\n",
    "input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights_0_1.shape:  (3, 2)\n",
      "weights_1_2.shape:  (2, 3)\n",
      "weights_2_3.shape:  (2, 2)\n",
      "weights_3_4.shape:  (1, 2)\n"
     ]
    }
   ],
   "source": [
    "weights_0_1 = np.array([[0.2, 0.3], [0, 0.1], [0, 0.1]])\n",
    "print(\"weights_0_1.shape: \", weights_0_1.shape)\n",
    "\n",
    "weights_1_2 = np.array([[0.2, 0.1, 0], [0, 0.1, 0.2]])\n",
    "print(\"weights_1_2.shape: \", weights_1_2.shape)\n",
    "\n",
    "weights_2_3 = np.array([[0.2, 0], [0, 0.1]])\n",
    "print(\"weights_2_3.shape: \", weights_2_3.shape)\n",
    "\n",
    "weights_3_4 = np.array([[0.1, 0.1]])\n",
    "print(\"weights_3_4.shape: \", weights_3_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Error:  0.49750312500000005\n",
      "Delta output:  [[-0.9975]]\n",
      "[[0.20399   0.0029925 0.001995 ]\n",
      " [0.30399   0.1029925 0.101995 ]] [[0.209975  0.0049875]\n",
      " [0.101995  0.1009975]\n",
      " [0.001995  0.2009975]] [[0.2109725 0.0109725]\n",
      " [0.0029925 0.1029925]] [[0.121945 ]\n",
      " [0.1029925]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1):\n",
    "    output_error = 0\n",
    "\n",
    "    layer_0 = input1.T\n",
    "\n",
    "    layer_1 = relu(np.dot(layer_0,weights_0_1.T))\n",
    "    layer_2 = relu(np.dot(layer_1,weights_1_2.T))\n",
    "    layer_3 = relu(np.dot(layer_2,weights_2_3.T))\n",
    "\n",
    "    output = np.dot(layer_3,weights_3_4.T)\n",
    "    \n",
    "    # Half of mse loss\n",
    "    output_error += np.sum((output - output1) ** 2) / 2\n",
    "    print(\"Output Error: \", output_error)\n",
    "    \n",
    "    output_delta = (output - output1)\n",
    "    print(\"Delta output: \",output_delta)\n",
    "\n",
    "    layer_3_delta = output_delta.dot(weights_3_4)*relu2deriv(layer_3)        \n",
    "    layer_2_delta = layer_3_delta.dot(weights_2_3)*relu2deriv(layer_2)\n",
    "    layer_1_delta = layer_2_delta.dot(weights_1_2)*relu2deriv(layer_1)\n",
    "\n",
    "    weights_3_4 = weights_3_4.T - alpha * layer_3.T.dot(output_delta)\n",
    "    weights_2_3 = weights_2_3.T - alpha * layer_2.T.dot(layer_3_delta)\n",
    "    weights_1_2 = weights_1_2.T - alpha * layer_1.T.dot(layer_2_delta)\n",
    "    weights_0_1 = weights_0_1.T - alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "print(weights_0_1, weights_1_2, weights_2_3, weights_3_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
